{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "800b5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_raw_json(raw):\n",
    "    if not raw or pd.isna(raw):\n",
    "        return {\"answer\": None, \"confidence\": None, \"rationale\": None}\n",
    "\n",
    "    raw = str(raw)\n",
    "\n",
    "    # Step 1: Extract the 'raw' value if it's a dict-like wrapper\n",
    "    raw_match = re.search(r\"'raw':\\s*(.*)\", raw, re.DOTALL)\n",
    "    if raw_match:\n",
    "        raw = raw_match.group(1).strip()\n",
    "        # Remove trailing comma or closing brace if present\n",
    "        raw = re.sub(r\"[},]\\s*$\", \"\", raw)\n",
    "\n",
    "    # Step 2: Remove ```json or ```\n",
    "    raw = re.sub(r\"```(?:json)?\", \"\", raw)\n",
    "\n",
    "    # Step 3: Normalize whitespace and line breaks\n",
    "    raw = raw.replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
    "\n",
    "    # Step 4: Convert single quotes to double quotes for simple key/value parsing\n",
    "    raw = raw.replace(\"'\", '\"')\n",
    "\n",
    "    # Step 5: Try to extract fields manually using regex\n",
    "    def extract_field(name):\n",
    "        pattern = rf'\"{name}\"\\s*:\\s*\"([^\"]*?)\"'\n",
    "        match = re.search(pattern, raw, re.DOTALL)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    answer = extract_field(\"answer\")\n",
    "    confidence = extract_field(\"confidence\")\n",
    "    rationale = extract_field(\"rationale\")\n",
    "\n",
    "    # Step 6: Try to parse confidence as float\n",
    "    try:\n",
    "        confidence = float(confidence) if confidence is not None else None\n",
    "    except:\n",
    "        confidence = None\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"confidence\": confidence,\n",
    "        \"rationale\": rationale\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df041db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "models = [\"llava-v1.6-mistral-7b-hf\", \"Qwen2.5-VL-7B-Instruct\"]\n",
    "datasets = [\"cvr\", \"bp\", \"marsvqa\", \"raven\"]\n",
    "ver = \"ver1\"\n",
    "strategies = [\"classification\", \"direct\", \"contrastive\", \"descriptive\"]\n",
    "results = [\"results\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for strategy in strategies:\n",
    "        for model in models:\n",
    "            for result in results:\n",
    "                print(f\"Processing: {dataset} | {strategy} | {model} | {ver}\")\n",
    "                df = pd.read_csv(\n",
    "                    f\"../results/{dataset}/{strategy}/{model}/{ver}/{result}.csv\",\n",
    "                    dtype={\"problem_id\": str}, \n",
    "                )\n",
    "\n",
    "                df[\"problem_id\"] = df[\"problem_id\"].str.strip()\n",
    "\n",
    "                mask = df[\"answer\"].isna() | df[\"confidence\"].isna() | df[\"rationale\"].isna() | (df[\"answer\"] == '')\n",
    "                print(mask.sum(), \"rows to fix\")\n",
    "\n",
    "                parsed = df.loc[mask, \"raw_response\"].apply(parse_raw_json)\n",
    "\n",
    "                df.loc[mask, \"answer\"] = parsed.apply(lambda x: x[\"answer\"])\n",
    "                df.loc[mask, \"confidence\"] = parsed.apply(lambda x: x[\"confidence\"])\n",
    "                df.loc[mask, \"rationale\"] = parsed.apply(lambda x: x[\"rationale\"])\n",
    "\n",
    "                df.to_csv(f\"../results/{dataset}/{strategy}/{model}/{ver}/{result}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea487e8b",
   "metadata": {},
   "source": [
    "# To run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6b62e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UPDATED] ../results/bp/classification/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/classification/InternVL3-8B/ver1/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/classification/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/direct/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/direct/llava-v1.6-mistral-7b-hf/ver2/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/direct/InternVL3-8B/ver1/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/direct/Qwen2.5-VL-32B-Instruct/ver1/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/direct/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/contrastive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/contrastive/InternVL3-8B/ver1/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/contrastive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/descriptive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/bp/descriptive/llava-v1.6-mistral-7b-hf/ver2/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/descriptive/InternVL3-8B/ver1/metadata.json → task_type=open-ended\n",
      "[UPDATED] ../results/bp/descriptive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=open-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/classification/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/classification/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/raven/classification/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/direct/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/direct/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/raven/direct/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/contrastive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/contrastive/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/raven/contrastive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/descriptive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/raven/descriptive/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/raven/descriptive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/classification/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/classification/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/cvr/classification/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/direct/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/direct/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/cvr/direct/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/contrastive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/contrastive/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/cvr/contrastive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/descriptive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/cvr/descriptive/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/cvr/descriptive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/classification/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/classification/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/marsvqa/classification/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/direct/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/direct/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/marsvqa/direct/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/contrastive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/contrastive/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/marsvqa/contrastive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/contrastive/Qwen2.5-VL-7B-Instruct/ver2/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/descriptive/llava-v1.6-mistral-7b-hf/ver1/metadata.json → task_type=close-ended, param_set_number=1\n",
      "[UPDATED] ../results/marsvqa/descriptive/InternVL3-8B/ver1/metadata.json → task_type=close-ended\n",
      "[UPDATED] ../results/marsvqa/descriptive/Qwen2.5-VL-7B-Instruct/ver1/metadata.json → task_type=close-ended, param_set_number=1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def infer_task_type(dataset_value: str) -> str:\n",
    "    return \"open-ended\" if dataset_value == \"bp\" else \"close-ended\"\n",
    "\n",
    "\n",
    "def insert_task_type(config: OrderedDict, task_type_value: str) -> OrderedDict:\n",
    "    \"\"\"\n",
    "    Insert 'task_type' between 'image_format' and 'category'.\n",
    "    \"\"\"\n",
    "    if \"task_type\" in config:\n",
    "        return config\n",
    "\n",
    "    new_config = OrderedDict()\n",
    "    inserted = False\n",
    "\n",
    "    for key, value in config.items():\n",
    "        new_config[key] = value\n",
    "        if key == \"image_format\":\n",
    "            new_config[\"task_type\"] = task_type_value\n",
    "            inserted = True\n",
    "\n",
    "    if not inserted:\n",
    "        raise KeyError(\"'image_format' not found in config\")\n",
    "\n",
    "    return new_config\n",
    "\n",
    "\n",
    "def process_metadata_file(path: Path, dry_run: bool):\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f, object_pairs_hook=OrderedDict)\n",
    "\n",
    "    dataset = data.get(\"dataset\")\n",
    "    if dataset is None:\n",
    "        print(f\"[SKIP] No dataset field: {path}\")\n",
    "        return\n",
    "\n",
    "    if \"config\" not in data:\n",
    "        print(f\"[SKIP] No config section: {path}\")\n",
    "        return\n",
    "\n",
    "    # Insert task_type\n",
    "    task_type_value = infer_task_type(dataset)\n",
    "    try:\n",
    "        new_config = insert_task_type(data[\"config\"], task_type_value)\n",
    "    except KeyError as e:\n",
    "        print(f\"[ERROR] {e} in {path}\")\n",
    "        return\n",
    "\n",
    "    data[\"config\"] = new_config\n",
    "\n",
    "    # Update param_set_number if null\n",
    "    if data.get(\"param_set_number\") is None:\n",
    "        data[\"param_set_number\"] = 1\n",
    "        param_set_updated = True\n",
    "    else:\n",
    "        param_set_updated = False\n",
    "\n",
    "    if dry_run:\n",
    "        updates = []\n",
    "        if \"task_type\" in new_config:\n",
    "            updates.append(f\"task_type={task_type_value}\")\n",
    "        if param_set_updated:\n",
    "            updates.append(\"param_set_number=1\")\n",
    "        print(f\"[DRY-RUN] Would update: {path} → {', '.join(updates)}\")\n",
    "        return\n",
    "\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    updates = [f\"task_type={task_type_value}\"]\n",
    "    if param_set_updated:\n",
    "        updates.append(\"param_set_number=1\")\n",
    "    print(f\"[UPDATED] {path} → {', '.join(updates)}\")\n",
    "\n",
    "\n",
    "results_dir = Path(\"../results\")\n",
    "if not results_dir.exists():\n",
    "    raise FileNotFoundError(\"results directory does not exist\")\n",
    "\n",
    "for metadata_path in results_dir.rglob(\"metadata.json\"):\n",
    "    process_metadata_file(metadata_path, dry_run=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66995dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UPDATED] ../results/ensembles/bp/majority/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/bp/confidence/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/bp/reasoning_with_image/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/bp/reasoning/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/raven/majority/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/raven/confidence/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/raven/reasoning_with_image/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/raven/reasoning/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/cvr/majority/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/cvr/confidence/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/cvr/reasoning_with_image/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/cvr/reasoning/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/marsvqa/majority/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/marsvqa/confidence/ensemble_ver1/ensemble_config.json\n",
      "[UPDATED] ../results/ensembles/marsvqa/reasoning/ensemble_ver1/ensemble_config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "def infer_task_type(dataset_value: str) -> str:\n",
    "    \"\"\"Return task_type based on dataset\"\"\"\n",
    "    return \"open-ended\" if dataset_value == \"bp\" else \"close-ended\"\n",
    "\n",
    "def insert_task_type(config: OrderedDict, task_type_value: str) -> OrderedDict:\n",
    "    \"\"\"Insert task_type between image_format and category if missing\"\"\"\n",
    "    if \"task_type\" in config:\n",
    "        return config\n",
    "\n",
    "    new_config = OrderedDict()\n",
    "    inserted = False\n",
    "    for key, value in config.items():\n",
    "        new_config[key] = value\n",
    "        if key == \"image_format\":\n",
    "            new_config[\"task_type\"] = task_type_value\n",
    "            inserted = True\n",
    "\n",
    "    if not inserted:\n",
    "        raise KeyError(\"'image_format' not found in config\")\n",
    "    return new_config\n",
    "\n",
    "def process_member(member: OrderedDict) -> bool:\n",
    "    \"\"\"\n",
    "    Update a single member dictionary.\n",
    "    Returns True if any change was made.\n",
    "    \"\"\"\n",
    "    changed = False\n",
    "    dataset = member.get(\"dataset\")\n",
    "    if not dataset:\n",
    "        return False\n",
    "\n",
    "    # Update param_set_number\n",
    "    if member.get(\"param_set_number\") is None:\n",
    "        member[\"param_set_number\"] = 1\n",
    "        changed = True\n",
    "\n",
    "    # Update config\n",
    "    if \"config\" in member:\n",
    "        try:\n",
    "            new_config = insert_task_type(member[\"config\"], infer_task_type(dataset))\n",
    "            if new_config != member[\"config\"]:\n",
    "                member[\"config\"] = new_config\n",
    "                changed = True\n",
    "        except KeyError as e:\n",
    "            print(f\"[ERROR] {e} in member with dataset {dataset}\")\n",
    "    return changed\n",
    "\n",
    "def process_ensemble_file(file_path: Path, dry_run: bool = False):\n",
    "    \"\"\"Process one ensemble_config.json file\"\"\"\n",
    "    with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f, object_pairs_hook=OrderedDict)\n",
    "\n",
    "    changed = False\n",
    "    # Iterate over all members\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict) and key.startswith(\"member_\"):\n",
    "            if process_member(value):\n",
    "                changed = True\n",
    "\n",
    "    if not changed:\n",
    "        print(f\"[SKIP] No changes needed for {file_path}\")\n",
    "        return\n",
    "\n",
    "    if dry_run:\n",
    "        print(f\"[DRY-RUN] Would update {file_path}\")\n",
    "        return\n",
    "\n",
    "    with file_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"[UPDATED] {file_path}\")\n",
    "\n",
    "results_dir = Path(\"../results/ensembles\")  \n",
    "if not results_dir.exists():\n",
    "    raise FileNotFoundError(f\"{results_dir} does not exist\")\n",
    "\n",
    "for ensemble_path in results_dir.rglob(\"ensemble_config.json\"):\n",
    "    process_ensemble_file(ensemble_path, dry_run=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9284de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = pd.read_csv(\"../results/all_results_concat.csv\", dtype={\"problem_id\": str})\n",
    "\n",
    "path = \"../results/bp/classification/Qwen2.5-VL-7B-Instruct/ver1/\"\n",
    "results_path = os.path.join(path, \"results.csv\")\n",
    "evaluation_results_path = os.path.join(path, \"evaluation_results.csv\")\n",
    "df1 = pd.read_csv(results_path, dtype={\"problem_id\": str})\n",
    "df2 = pd.read_csv(evaluation_results_path, dtype={\"problem_id\": str})\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# JSON string\n",
    "raw_json = '''{\n",
    "  \"answer\": \"A\",\n",
    "  \"confidence\": 0.9,\n",
    "  \"rationale\": \"In set A, all images on the left side share the same property: they are all composed of straight lines. This rule is applied consistently. On the right side, no image shares this property, confirming the rule's exclusivity. In set B, one image H on the right side also fits the property of being composed of straight lines, indicating a switch.\"\n",
    "}'''\n",
    "\n",
    "data = json.loads(raw_json)\n",
    "\n",
    "# Boolean mask for the row\n",
    "mask = (\n",
    "    (df[\"problem_id\"] == \"087\") &\n",
    "    (df[\"dataset_name\"] == \"bp\") &\n",
    "    (df[\"model_name\"] == \"Qwen/Qwen2.5-VL-7B-Instruct\") &\n",
    "    (df[\"version\"] == 1) &\n",
    "    (df[\"strategy_name\"] == \"classification\")\n",
    ")\n",
    "\n",
    "mask1 = df1[\"problem_id\"] == \"087\"\n",
    "\n",
    "# Select the row as a DataFrame\n",
    "row_df = df.loc[mask]\n",
    "\n",
    "# Populate the fields in the original df\n",
    "df.loc[mask, [\"answer\", \"rationale\", \"confidence\"]] = [data[\"answer\"], data[\"rationale\"], data[\"confidence\"]]\n",
    "df1.loc[mask1, [\"answer\", \"rationale\", \"confidence\"]] = [data[\"answer\"], data[\"rationale\"], data[\"confidence\"]]\n",
    "df2.loc[mask1, [\"answer\", \"rationale\", \"confidence\"]] = [data[\"answer\"], data[\"rationale\"], data[\"confidence\"]]\n",
    "df2.loc[mask1, \"score\"] = \"Right\"\n",
    "\n",
    "df.to_csv(\"../results/all_results_concat.csv\", index=False)\n",
    "df1.to_csv(results_path, index=False)\n",
    "df2.to_csv(evaluation_results_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee451fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"../results/bp/classification/Qwen2.5-VL-7B-Instruct/ver1/\"\n",
    "\n",
    "summary_path = os.path.join(path, \"evaluation_results_summary.json\")\n",
    "metrics_path = os.path.join(path, \"evaluation_results_metrics.json\")\n",
    "\n",
    "with open(metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if \"bin_counts\" in data and \"No answer provided\" in data[\"bin_counts\"]:\n",
    "    data[\"bin_counts\"][\"No answer provided\"] = 0\n",
    "    data[\"bin_counts\"][\"Right\"] = 44\n",
    "\n",
    "with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def replace_ones_with_zero(d: dict):\n",
    "    for k, v in d.items():\n",
    "        if v > 0:\n",
    "            d[k] = 0\n",
    "\n",
    "if \"answers_completeness\" in data:\n",
    "    if \"missing_count_per_column\" in data[\"answers_completeness\"]:\n",
    "        replace_ones_with_zero(data[\"answers_completeness\"][\"missing_count_per_column\"])\n",
    "\n",
    "    if \"row_ids_with_any_missing\" in data[\"answers_completeness\"]:\n",
    "        data[\"answers_completeness\"][\"row_ids_with_any_missing\"] = []\n",
    "\n",
    "    if \"missing_ratio_per_column\" in data[\"answers_completeness\"]:\n",
    "        replace_ones_with_zero(data[\"answers_completeness\"][\"missing_ratio_per_column\"])\n",
    "\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "632fc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: ../results/ensembles/bp/majority/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/bp/confidence/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/bp/reasoning_with_image/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/bp/reasoning/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/raven/majority/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/raven/confidence/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/raven/reasoning_with_image/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/raven/reasoning/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/cvr/majority/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/cvr/confidence/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/cvr/reasoning_with_image/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/cvr/reasoning/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/marsvqa/majority/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/marsvqa/confidence/ensemble_ver1/ensemble_config.json\n",
      "Updated: ../results/ensembles/marsvqa/reasoning/ensemble_ver1/ensemble_config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "ensemble_dir = \"../results/ensembles\"\n",
    "\n",
    "for root, dirs, files in os.walk(ensemble_dir):\n",
    "    for file in files:\n",
    "        if file == \"ensemble_config.json\":\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Load JSON\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            new_data = OrderedDict()\n",
    "            \n",
    "            # Get member_0 info\n",
    "            member0 = data.get(\"member_0\", {})\n",
    "            member0_config = member0.get(\"config\", {})\n",
    "            problem_description = member0.get(\"problem_description_prompt\", \"\")\n",
    "            sample_answer = member0.get(\"sample_answer_prompt\", \"\")\n",
    "            \n",
    "            # 1. Insert task_type, category, dataset at the beginning\n",
    "            for key in [\"task_type\", \"category\", \"dataset\"]:\n",
    "                if key in member0_config:\n",
    "                    new_data[key] = member0_config[key]\n",
    "                elif key in member0:\n",
    "                    new_data[key] = member0[key]\n",
    "                    \n",
    "            # 2. Process ensemble_model and main_prompt\n",
    "            for key, value in data.items():\n",
    "                if key == \"ensemble_model\" and value == \"\":\n",
    "                    new_data[key] = \"No judge model needed for this type and dataset\"\n",
    "                elif key == \"main_prompt\" and value:\n",
    "                    # Replace placeholders with actual prompts\n",
    "                    new_prompt = value.replace(\"$problem_description\", problem_description)\\\n",
    "                                      .replace(\"$sample_answer\", sample_answer)\n",
    "                    new_data[key] = new_prompt\n",
    "                else:\n",
    "                    new_data[key] = value\n",
    "            \n",
    "            # Save updated JSON\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(new_data, f, indent=4)\n",
    "            \n",
    "            print(f\"Updated: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3a91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
