{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21de4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c176373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_correct(df, half_scores = False):\n",
    "    df = df.copy()\n",
    "    if half_scores:\n",
    "        df['is_correct'] = df['score'].apply(\n",
    "            lambda x: 1 if str(x).strip().lower() == 'right'\n",
    "            else 0.5 if str(x).strip().lower() == 'somewhat right' \n",
    "            else 0\n",
    "            )\n",
    "    else:\n",
    "        df['is_correct'] = df['score'].apply(\n",
    "            lambda x: 1 if str(x).strip().lower() == 'right' \n",
    "            else 0\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def clean_df(df, subset_cols,):\n",
    "    df = df.copy()\n",
    "    df = df.dropna(subset=subset_cols).drop_duplicates(subset=subset_cols, keep='last')\n",
    "    return df\n",
    "\n",
    "def prepare_df(df, half_scores = False):\n",
    "    df = df.copy()\n",
    "    df = fill_correct(df, half_scores=half_scores)\n",
    "    ensemble_subset_cols = [\n",
    "            \"problem_id\",\n",
    "            \"dataset_name\",\n",
    "            \"type_name\",\n",
    "            \"version\",\n",
    "        ]\n",
    "    \n",
    "    single_subset_cols = [\n",
    "            \"problem_id\",\n",
    "            \"dataset_name\",\n",
    "            \"model_name\",\n",
    "            \"strategy_name\",\n",
    "            \"version\"\n",
    "        ]\n",
    "    df_singles = df[df[\"ensemble\"] == False]\n",
    "    df_singles = clean_df(df_singles, subset_cols=single_subset_cols)\n",
    "    df_ensembles = df[df[\"ensemble\"] == True]\n",
    "    df_ensembles = clean_df(df_ensembles, subset_cols=ensemble_subset_cols)\n",
    "    return df_singles, df_ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f3b9705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>confidence</th>\n",
       "      <th>rationale</th>\n",
       "      <th>raw_response</th>\n",
       "      <th>score</th>\n",
       "      <th>key</th>\n",
       "      <th>type_name</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>judge_rationale</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy_name</th>\n",
       "      <th>version</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In Set D, there's no consistent majority rule ...</td>\n",
       "      <td>{'answer': 'D', 'confidence': 1.0, 'rationale'...</td>\n",
       "      <td>Wrong</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cvr</td>\n",
       "      <td>Qwen/Qwen2.5-VL-7B-Instruct</td>\n",
       "      <td>classification</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Set C has all images with a consistent number ...</td>\n",
       "      <td>{'answer': 'C', 'confidence': 0.9, 'rationale'...</td>\n",
       "      <td>Wrong</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cvr</td>\n",
       "      <td>Qwen/Qwen2.5-VL-7B-Instruct</td>\n",
       "      <td>classification</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9</td>\n",
       "      <td>In Set D, there is no clear majority rule that...</td>\n",
       "      <td>{'answer': 'D', 'confidence': 0.9, 'rationale'...</td>\n",
       "      <td>Right</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cvr</td>\n",
       "      <td>Qwen/Qwen2.5-VL-7B-Instruct</td>\n",
       "      <td>classification</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9</td>\n",
       "      <td>In Set D, all visible images share the same nu...</td>\n",
       "      <td>{'answer': 'D', 'confidence': 0.9, 'rationale'...</td>\n",
       "      <td>Wrong</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cvr</td>\n",
       "      <td>Qwen/Qwen2.5-VL-7B-Instruct</td>\n",
       "      <td>classification</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In set D, all visible images share a similar p...</td>\n",
       "      <td>{'answer': 'D', 'confidence': 1.0, 'rationale'...</td>\n",
       "      <td>Wrong</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cvr</td>\n",
       "      <td>Qwen/Qwen2.5-VL-7B-Instruct</td>\n",
       "      <td>classification</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     problem_id answer  confidence  \\\n",
       "100           0      D         1.0   \n",
       "101           1      C         0.9   \n",
       "102           2      D         0.9   \n",
       "103           3      D         0.9   \n",
       "104           4      D         1.0   \n",
       "\n",
       "                                             rationale  \\\n",
       "100  In Set D, there's no consistent majority rule ...   \n",
       "101  Set C has all images with a consistent number ...   \n",
       "102  In Set D, there is no clear majority rule that...   \n",
       "103  In Set D, all visible images share the same nu...   \n",
       "104  In set D, all visible images share a similar p...   \n",
       "\n",
       "                                          raw_response  score key type_name  \\\n",
       "100  {'answer': 'D', 'confidence': 1.0, 'rationale'...  Wrong   C       NaN   \n",
       "101  {'answer': 'C', 'confidence': 0.9, 'rationale'...  Wrong   A       NaN   \n",
       "102  {'answer': 'D', 'confidence': 0.9, 'rationale'...  Right   D       NaN   \n",
       "103  {'answer': 'D', 'confidence': 0.9, 'rationale'...  Wrong   C       NaN   \n",
       "104  {'answer': 'D', 'confidence': 1.0, 'rationale'...  Wrong   B       NaN   \n",
       "\n",
       "     ensemble judge_rationale reasoning dataset_name  \\\n",
       "100     False             NaN       NaN          cvr   \n",
       "101     False             NaN       NaN          cvr   \n",
       "102     False             NaN       NaN          cvr   \n",
       "103     False             NaN       NaN          cvr   \n",
       "104     False             NaN       NaN          cvr   \n",
       "\n",
       "                      model_name   strategy_name  version  is_correct  \n",
       "100  Qwen/Qwen2.5-VL-7B-Instruct  classification        1         0.0  \n",
       "101  Qwen/Qwen2.5-VL-7B-Instruct  classification        1         0.0  \n",
       "102  Qwen/Qwen2.5-VL-7B-Instruct  classification        1         1.0  \n",
       "103  Qwen/Qwen2.5-VL-7B-Instruct  classification        1         0.0  \n",
       "104  Qwen/Qwen2.5-VL-7B-Instruct  classification        1         0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('results/all_results_concat.csv')\n",
    "df = prepare_df(df, half_scores=True)[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca769c",
   "metadata": {},
   "source": [
    "### Top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bfc6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_stats(\n",
    "    df,\n",
    "    group_cols,\n",
    "    versions=(1, 3),\n",
    "    top_n=10,\n",
    "    bottom_n=10,\n",
    "    return_top_k=5\n",
    "):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter versions\n",
    "    df = df[df[\"version\"].isin(versions)]\n",
    "\n",
    "    # Group and aggregate\n",
    "    grouped = df.groupby(group_cols)[\"is_correct\"]\n",
    "\n",
    "    score = grouped.sum()\n",
    "    total = grouped.count()\n",
    "\n",
    "    percentage = score / total * 100\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"total_score\": score,\n",
    "        \"percentage\": percentage\n",
    "    }).reset_index()\n",
    "\n",
    "    # Sort\n",
    "    top = results.sort_values(\"percentage\", ascending=False).head(top_n)\n",
    "    bottom = results.sort_values(\"percentage\", ascending=True).head(bottom_n)\n",
    "\n",
    "    print(f\"\\nTop {top_n}:\")\n",
    "    print(top)\n",
    "\n",
    "    print(f\"\\nBottom {bottom_n}:\")\n",
    "    print(bottom)\n",
    "\n",
    "    # ---- Top K list in requested format ----\n",
    "    top_k_list = [\n",
    "        [str(row[col]) for col in group_cols]\n",
    "        for _, row in top.head(return_top_k).iterrows()\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nTop {return_top_k} {[f'{c}' for c in group_cols]}:\")\n",
    "    print(top_k_list)\n",
    "\n",
    "    return top_k_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80e017ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10:\n",
      "     strategy_name                   model_name  version  total_score  \\\n",
      "21          direct  Qwen/Qwen2.5-VL-7B-Instruct        3        196.0   \n",
      "9      contrastive  Qwen/Qwen2.5-VL-7B-Instruct        3        193.0   \n",
      "20          direct  Qwen/Qwen2.5-VL-7B-Instruct        1        190.5   \n",
      "8      contrastive  Qwen/Qwen2.5-VL-7B-Instruct        1        172.5   \n",
      "18          direct       OpenGVLab/InternVL3-8B        1        126.0   \n",
      "12     descriptive       OpenGVLab/InternVL3-8B        1        124.0   \n",
      "2   classification  Qwen/Qwen2.5-VL-7B-Instruct        1        122.0   \n",
      "3   classification  Qwen/Qwen2.5-VL-7B-Instruct        3        119.0   \n",
      "19          direct       OpenGVLab/InternVL3-8B        3        117.5   \n",
      "13     descriptive       OpenGVLab/InternVL3-8B        3        117.0   \n",
      "\n",
      "    percentage  \n",
      "21   49.000000  \n",
      "9    48.250000  \n",
      "20   47.625000  \n",
      "8    43.233083  \n",
      "18   31.500000  \n",
      "12   31.000000  \n",
      "2    30.500000  \n",
      "3    29.750000  \n",
      "19   29.375000  \n",
      "13   29.250000  \n",
      "\n",
      "Bottom 10:\n",
      "     strategy_name                         model_name  version  total_score  \\\n",
      "10     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        1         86.0   \n",
      "23          direct  llava-hf/llava-v1.6-mistral-7b-hf        3         93.0   \n",
      "6      contrastive             OpenGVLab/InternVL3-8B        1         93.5   \n",
      "11     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        3         93.5   \n",
      "22          direct  llava-hf/llava-v1.6-mistral-7b-hf        1         96.0   \n",
      "16     descriptive  llava-hf/llava-v1.6-mistral-7b-hf        1         98.0   \n",
      "4   classification  llava-hf/llava-v1.6-mistral-7b-hf        1         99.0   \n",
      "17     descriptive  llava-hf/llava-v1.6-mistral-7b-hf        3        102.0   \n",
      "5   classification  llava-hf/llava-v1.6-mistral-7b-hf        3        104.0   \n",
      "7      contrastive             OpenGVLab/InternVL3-8B        3        106.0   \n",
      "\n",
      "    percentage  \n",
      "10      21.500  \n",
      "23      23.250  \n",
      "6       23.375  \n",
      "11      23.375  \n",
      "22      24.000  \n",
      "16      24.500  \n",
      "4       24.750  \n",
      "17      25.500  \n",
      "5       26.000  \n",
      "7       26.500  \n",
      "\n",
      "Top 5 ['strategy_name', 'model_name', 'version']:\n",
      "[['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '3'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '3'], ['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '1'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '1'], ['direct', 'OpenGVLab/InternVL3-8B', '1']]\n",
      "\n",
      " ------------ BP -------------\n",
      "\n",
      "\n",
      "Top 10:\n",
      "   strategy_name                         model_name  version dataset_name  \\\n",
      "12        direct             OpenGVLab/InternVL3-8B        1           bp   \n",
      "13        direct             OpenGVLab/InternVL3-8B        3           bp   \n",
      "6    descriptive             OpenGVLab/InternVL3-8B        1           bp   \n",
      "2    contrastive        Qwen/Qwen2.5-VL-7B-Instruct        1           bp   \n",
      "8    descriptive        Qwen/Qwen2.5-VL-7B-Instruct        1           bp   \n",
      "9    descriptive        Qwen/Qwen2.5-VL-7B-Instruct        3           bp   \n",
      "15        direct        Qwen/Qwen2.5-VL-7B-Instruct        3           bp   \n",
      "10   descriptive  llava-hf/llava-v1.6-mistral-7b-hf        1           bp   \n",
      "14        direct        Qwen/Qwen2.5-VL-7B-Instruct        1           bp   \n",
      "7    descriptive             OpenGVLab/InternVL3-8B        3           bp   \n",
      "\n",
      "    total_score  percentage  \n",
      "12         44.0        44.0  \n",
      "13         42.5        42.5  \n",
      "6          41.0        41.0  \n",
      "2          40.5        40.5  \n",
      "8          40.5        40.5  \n",
      "9          38.5        38.5  \n",
      "15         38.0        38.0  \n",
      "10         38.0        38.0  \n",
      "14         37.5        37.5  \n",
      "7          37.0        37.0  \n",
      "\n",
      "Bottom 10:\n",
      "   strategy_name                         model_name  version dataset_name  \\\n",
      "4    contrastive  llava-hf/llava-v1.6-mistral-7b-hf        1           bp   \n",
      "5    contrastive  llava-hf/llava-v1.6-mistral-7b-hf        3           bp   \n",
      "17        direct  llava-hf/llava-v1.6-mistral-7b-hf        3           bp   \n",
      "1    contrastive             OpenGVLab/InternVL3-8B        3           bp   \n",
      "0    contrastive             OpenGVLab/InternVL3-8B        1           bp   \n",
      "16        direct  llava-hf/llava-v1.6-mistral-7b-hf        1           bp   \n",
      "11   descriptive  llava-hf/llava-v1.6-mistral-7b-hf        3           bp   \n",
      "3    contrastive        Qwen/Qwen2.5-VL-7B-Instruct        3           bp   \n",
      "7    descriptive             OpenGVLab/InternVL3-8B        3           bp   \n",
      "14        direct        Qwen/Qwen2.5-VL-7B-Instruct        1           bp   \n",
      "\n",
      "    total_score  percentage  \n",
      "4          30.0        30.0  \n",
      "5          32.5        32.5  \n",
      "17         34.0        34.0  \n",
      "1          34.0        34.0  \n",
      "0          34.5        34.5  \n",
      "16         35.0        35.0  \n",
      "11         36.0        36.0  \n",
      "3          36.0        36.0  \n",
      "7          37.0        37.0  \n",
      "14         37.5        37.5  \n",
      "\n",
      "Top 5 ['strategy_name', 'model_name', 'version', 'dataset_name']:\n",
      "[['direct', 'OpenGVLab/InternVL3-8B', '1', 'bp'], ['direct', 'OpenGVLab/InternVL3-8B', '3', 'bp'], ['descriptive', 'OpenGVLab/InternVL3-8B', '1', 'bp'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'bp'], ['descriptive', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'bp']]\n",
      "\n",
      " ------------ CVR -------------\n",
      "\n",
      "\n",
      "Top 10:\n",
      "     strategy_name                   model_name  version dataset_name  \\\n",
      "2   classification  Qwen/Qwen2.5-VL-7B-Instruct        1          cvr   \n",
      "21          direct  Qwen/Qwen2.5-VL-7B-Instruct        3          cvr   \n",
      "9      contrastive  Qwen/Qwen2.5-VL-7B-Instruct        3          cvr   \n",
      "18          direct       OpenGVLab/InternVL3-8B        1          cvr   \n",
      "1   classification       OpenGVLab/InternVL3-8B        3          cvr   \n",
      "0   classification       OpenGVLab/InternVL3-8B        1          cvr   \n",
      "12     descriptive       OpenGVLab/InternVL3-8B        1          cvr   \n",
      "15     descriptive  Qwen/Qwen2.5-VL-7B-Instruct        3          cvr   \n",
      "8      contrastive  Qwen/Qwen2.5-VL-7B-Instruct        1          cvr   \n",
      "19          direct       OpenGVLab/InternVL3-8B        3          cvr   \n",
      "\n",
      "    total_score  percentage  \n",
      "2          43.0        43.0  \n",
      "21         39.0        39.0  \n",
      "9          38.0        38.0  \n",
      "18         38.0        38.0  \n",
      "1          36.0        36.0  \n",
      "0          35.0        35.0  \n",
      "12         32.0        32.0  \n",
      "15         31.0        31.0  \n",
      "8          31.0        31.0  \n",
      "19         31.0        31.0  \n",
      "\n",
      "Bottom 10:\n",
      "     strategy_name                         model_name  version dataset_name  \\\n",
      "10     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        1          cvr   \n",
      "22          direct  llava-hf/llava-v1.6-mistral-7b-hf        1          cvr   \n",
      "11     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        3          cvr   \n",
      "5   classification  llava-hf/llava-v1.6-mistral-7b-hf        3          cvr   \n",
      "4   classification  llava-hf/llava-v1.6-mistral-7b-hf        1          cvr   \n",
      "6      contrastive             OpenGVLab/InternVL3-8B        1          cvr   \n",
      "16     descriptive  llava-hf/llava-v1.6-mistral-7b-hf        1          cvr   \n",
      "7      contrastive             OpenGVLab/InternVL3-8B        3          cvr   \n",
      "23          direct  llava-hf/llava-v1.6-mistral-7b-hf        3          cvr   \n",
      "3   classification        Qwen/Qwen2.5-VL-7B-Instruct        3          cvr   \n",
      "\n",
      "    total_score  percentage  \n",
      "10         14.0        14.0  \n",
      "22         20.0        20.0  \n",
      "11         21.0        21.0  \n",
      "5          21.0        21.0  \n",
      "4          22.0        22.0  \n",
      "6          23.0        23.0  \n",
      "16         25.0        25.0  \n",
      "7          25.0        25.0  \n",
      "23         26.0        26.0  \n",
      "3          28.0        28.0  \n",
      "\n",
      "Top 5 ['strategy_name', 'model_name', 'version', 'dataset_name']:\n",
      "[['classification', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'cvr'], ['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'cvr'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'cvr'], ['direct', 'OpenGVLab/InternVL3-8B', '1', 'cvr'], ['classification', 'OpenGVLab/InternVL3-8B', '3', 'cvr']]\n",
      "\n",
      " ------------ RAVEN -------------\n",
      "\n",
      "\n",
      "Top 10:\n",
      "   strategy_name                         model_name  version dataset_name  \\\n",
      "9    contrastive        Qwen/Qwen2.5-VL-7B-Instruct        3        raven   \n",
      "21        direct        Qwen/Qwen2.5-VL-7B-Instruct        3        raven   \n",
      "20        direct        Qwen/Qwen2.5-VL-7B-Instruct        1        raven   \n",
      "8    contrastive        Qwen/Qwen2.5-VL-7B-Instruct        1        raven   \n",
      "12   descriptive             OpenGVLab/InternVL3-8B        1        raven   \n",
      "13   descriptive             OpenGVLab/InternVL3-8B        3        raven   \n",
      "15   descriptive        Qwen/Qwen2.5-VL-7B-Instruct        3        raven   \n",
      "18        direct             OpenGVLab/InternVL3-8B        1        raven   \n",
      "14   descriptive        Qwen/Qwen2.5-VL-7B-Instruct        1        raven   \n",
      "22        direct  llava-hf/llava-v1.6-mistral-7b-hf        1        raven   \n",
      "\n",
      "    total_score  percentage  \n",
      "9          84.0        84.0  \n",
      "21         82.0        82.0  \n",
      "20         81.0        81.0  \n",
      "8          65.0        65.0  \n",
      "12         26.0        26.0  \n",
      "13         25.0        25.0  \n",
      "15         23.0        23.0  \n",
      "18         20.0        20.0  \n",
      "14         19.0        19.0  \n",
      "22         16.0        16.0  \n",
      "\n",
      "Bottom 10:\n",
      "     strategy_name                         model_name  version dataset_name  \\\n",
      "5   classification  llava-hf/llava-v1.6-mistral-7b-hf        3        raven   \n",
      "16     descriptive  llava-hf/llava-v1.6-mistral-7b-hf        1        raven   \n",
      "4   classification  llava-hf/llava-v1.6-mistral-7b-hf        1        raven   \n",
      "10     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        1        raven   \n",
      "11     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        3        raven   \n",
      "23          direct  llava-hf/llava-v1.6-mistral-7b-hf        3        raven   \n",
      "19          direct             OpenGVLab/InternVL3-8B        3        raven   \n",
      "6      contrastive             OpenGVLab/InternVL3-8B        1        raven   \n",
      "7      contrastive             OpenGVLab/InternVL3-8B        3        raven   \n",
      "2   classification        Qwen/Qwen2.5-VL-7B-Instruct        1        raven   \n",
      "\n",
      "    total_score  percentage  \n",
      "5           8.0         8.0  \n",
      "16          9.0         9.0  \n",
      "4           9.0         9.0  \n",
      "10         10.0        10.0  \n",
      "11         11.0        11.0  \n",
      "23         11.0        11.0  \n",
      "19         13.0        13.0  \n",
      "6          14.0        14.0  \n",
      "7          14.0        14.0  \n",
      "2          15.0        15.0  \n",
      "\n",
      "Top 5 ['strategy_name', 'model_name', 'version', 'dataset_name']:\n",
      "[['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'raven'], ['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'raven'], ['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'raven'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'raven'], ['descriptive', 'OpenGVLab/InternVL3-8B', '1', 'raven']]\n",
      "\n",
      " ------------ MARS -------------\n",
      "\n",
      "\n",
      "Top 10:\n",
      "     strategy_name                         model_name  version dataset_name  \\\n",
      "20          direct        Qwen/Qwen2.5-VL-7B-Instruct        1      marsvqa   \n",
      "21          direct        Qwen/Qwen2.5-VL-7B-Instruct        3      marsvqa   \n",
      "8      contrastive        Qwen/Qwen2.5-VL-7B-Instruct        1      marsvqa   \n",
      "9      contrastive        Qwen/Qwen2.5-VL-7B-Instruct        3      marsvqa   \n",
      "7      contrastive             OpenGVLab/InternVL3-8B        3      marsvqa   \n",
      "10     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        1      marsvqa   \n",
      "19          direct             OpenGVLab/InternVL3-8B        3      marsvqa   \n",
      "5   classification  llava-hf/llava-v1.6-mistral-7b-hf        3      marsvqa   \n",
      "11     contrastive  llava-hf/llava-v1.6-mistral-7b-hf        3      marsvqa   \n",
      "3   classification        Qwen/Qwen2.5-VL-7B-Instruct        3      marsvqa   \n",
      "\n",
      "    total_score  percentage  \n",
      "20         43.0   43.000000  \n",
      "21         37.0   37.000000  \n",
      "8          36.0   36.363636  \n",
      "9          35.0   35.000000  \n",
      "7          33.0   33.000000  \n",
      "10         32.0   32.000000  \n",
      "19         31.0   31.000000  \n",
      "5          30.0   30.000000  \n",
      "11         29.0   29.000000  \n",
      "3          27.0   27.000000  \n",
      "\n",
      "Bottom 10:\n",
      "     strategy_name                         model_name  version dataset_name  \\\n",
      "1   classification             OpenGVLab/InternVL3-8B        3      marsvqa   \n",
      "17     descriptive  llava-hf/llava-v1.6-mistral-7b-hf        3      marsvqa   \n",
      "2   classification        Qwen/Qwen2.5-VL-7B-Instruct        1      marsvqa   \n",
      "4   classification  llava-hf/llava-v1.6-mistral-7b-hf        1      marsvqa   \n",
      "14     descriptive        Qwen/Qwen2.5-VL-7B-Instruct        1      marsvqa   \n",
      "23          direct  llava-hf/llava-v1.6-mistral-7b-hf        3      marsvqa   \n",
      "6      contrastive             OpenGVLab/InternVL3-8B        1      marsvqa   \n",
      "15     descriptive        Qwen/Qwen2.5-VL-7B-Instruct        3      marsvqa   \n",
      "18          direct             OpenGVLab/InternVL3-8B        1      marsvqa   \n",
      "12     descriptive             OpenGVLab/InternVL3-8B        1      marsvqa   \n",
      "\n",
      "    total_score  percentage  \n",
      "1          19.0        19.0  \n",
      "17         19.0        19.0  \n",
      "2          20.0        20.0  \n",
      "4          20.0        20.0  \n",
      "14         20.0        20.0  \n",
      "23         22.0        22.0  \n",
      "6          22.0        22.0  \n",
      "15         23.0        23.0  \n",
      "18         24.0        24.0  \n",
      "12         25.0        25.0  \n",
      "\n",
      "Top 5 ['strategy_name', 'model_name', 'version', 'dataset_name']:\n",
      "[['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'marsvqa'], ['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'marsvqa'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'marsvqa'], ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'marsvqa'], ['contrastive', 'OpenGVLab/InternVL3-8B', '3', 'marsvqa']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'marsvqa'],\n",
       " ['direct', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'marsvqa'],\n",
       " ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '1', 'marsvqa'],\n",
       " ['contrastive', 'Qwen/Qwen2.5-VL-7B-Instruct', '3', 'marsvqa'],\n",
       " ['contrastive', 'OpenGVLab/InternVL3-8B', '3', 'marsvqa']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = [\"strategy_name\", \"model_name\", \"version\"]\n",
    "accuracy_stats(df, group_cols=group_cols)\n",
    "\n",
    "bp_only = df[df[\"dataset_name\"]==\"bp\"].copy()\n",
    "bp_only = bp_only[bp_only[\"strategy_name\"]!=\"classification\"]\n",
    "cvr_only = df[df[\"dataset_name\"]==\"cvr\"].copy()\n",
    "raven_only = df[df[\"dataset_name\"]==\"raven\"].copy()\n",
    "mars_only = df[df[\"dataset_name\"]==\"marsvqa\"].copy()\n",
    "\n",
    "group_cols.append(\"dataset_name\")\n",
    "print(\"\\n ------------ BP -------------\\n\")\n",
    "accuracy_stats(bp_only, group_cols=group_cols)\n",
    "print(\"\\n ------------ CVR -------------\\n\")\n",
    "accuracy_stats(cvr_only, group_cols=group_cols)\n",
    "print(\"\\n ------------ RAVEN -------------\\n\")\n",
    "accuracy_stats(raven_only, group_cols=group_cols)\n",
    "print(\"\\n ------------ MARS -------------\\n\")\n",
    "accuracy_stats(mars_only, group_cols=group_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1a305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
